# Document Ingestion Workflow - Implementation Analysis

**Date**: 2025-08-22
**Analysis Target**: webapp-backend vs [document-ingestion-workflow-complete.md](../../../webapp/docs/document-ingestion-workflow-complete.md)
**Purpose**: Identify implementation gaps and provide actionable remediation plan

## Executive Summary

This analysis compares the current webapp-backend implementation against the comprehensive workflow specification. While the backend has solid foundations with well-structured APIs, models, and services, there are **significant gaps** in the processing pipeline, review workflow, and several missing critical endpoints that prevent the system from matching the designed user experience.

**Key Findings:**
- âœ… **Good Foundation**: API structure, authentication, models are well-implemented
- âŒ **Major Gaps**: Review queue endpoints, metadata update workflow, batch status calculation
- âŒ **Missing Features**: Library statistics, processing logs, webhook notifications
- âš ï¸ **Incomplete Pipeline**: Background processing implementation unclear

## Detailed Analysis by Component

---

## 1. API Endpoint Deviations

### 1.1 Missing Critical Endpoints

#### **ðŸ“Š Document Library Statistics**
**Expected**: `GET /api/documents/stats`
**Status**: âŒ **MISSING**
**Impact**: Frontend cannot display library statistics dashboard

```python
# Expected Response:
{
  "total_documents": 1247,
  "books_textbooks": 432,
  "articles_publications": 298,
  "statutes_codes": 156,
  "case_law": 245,
  "expert_reports": 89,
  "other_documents": 27
}
```

**Current State**: No endpoint exists for aggregated document counts by type.

#### **ðŸ“‹ Review Queue Management**
**Expected**: `GET /api/documents/queue`
**Status**: âŒ **MISSING**
**Impact**: Frontend cannot display documents pending human review

**Current Alternative**: `GET /api/processing/files/pending-review` exists but returns different data structure and lacks document metadata.

**Key Differences**:
```python
# Expected (from workflow spec):
{
  "queue": [{
    "id": "doc-id",
    "title": "AI-extracted title",
    "original_filename": "file.pdf",
    "doc_type": "case_law",
    "confidence_score": 0.85,
    "preview_text": "First 500 chars...",
    "processing_status": "review_pending"
  }]
}

# Current implementation returns:
{
  "files": [{
    "id": "file-id",
    "ai_title": "title",  # Different field name
    "ai_doc_type": "type", # Different field name
    # Missing: confidence_score, preview_text, document metadata
  }]
}
```

#### **ðŸ“ Document Metadata Update**
**Expected**: `PUT /api/documents/{document_id}/metadata`
**Status**: âŒ **MISSING**
**Impact**: Users cannot edit AI-extracted metadata during review

**Current Alternative**: Only approve/reject endpoints exist - no metadata editing capability.

#### **ðŸ“ˆ Processing Logs for UI**
**Expected**: `GET /api/processing/logs`
**Status**: âŒ **MISSING**
**Impact**: Frontend cannot display processing history and system activity

#### **ðŸ”„ Batch Status with Job Details**
**Expected**: `GET /api/processing/jobs/{job_id}`
**Status**: âš ï¸ **PARTIAL** - exists as `GET /api/documents/processing-status/{batch_id}`
**Impact**: Different endpoint pattern, may not include calculated batch status

### 1.2 Endpoint Naming and Structure Deviations

#### **Document Approval Flow**
**Expected Pattern**:
- `PUT /api/documents/{document_id}/metadata` (for editing)
- `POST /api/documents/{document_id}/approve` (for approval)

**Current Pattern**:
- `POST /api/documents/approve/{file_id}` (uses file_id instead of document_id)
- No metadata editing endpoint

**Issue**: The workflow expects document-centric operations, but current implementation uses file-centric IDs.

#### **Library Search and Filtering**
**Expected**: Rich search with text search, type/category filters, pagination
**Current**: Basic library listing with simple filters

**Missing Features**:
- Text search across title, summary, content
- Advanced pagination with `has_more` indicator
- Search result relevance scoring

---

## 2. Data Model and Schema Deviations

### 2.1 Database Schema Alignment

#### **âœ… Well Implemented**:
- Document types and categories using enums âœ…
- Citation field added âœ…
- firm_id removed as specified âœ…
- RLS policies enabled âœ…

#### **âŒ Missing Schema Elements**:

**Processing Jobs Table**:
```sql
-- Expected (from workflow):
ALTER TABLE processing_jobs
ADD COLUMN webhook_url text,
ADD COLUMN webhook_secret text,
ADD COLUMN last_webhook_at timestamp with time zone;
```
**Status**: Not verified in current schema

**Processing Files Error Tracking**:
```sql
-- Expected (from workflow):
ALTER TABLE processing_files
ADD COLUMN error_details jsonb,
ADD COLUMN retry_strategy text DEFAULT 'exponential_backoff';
```
**Status**: Partially implemented (error_details exists in model but not confirmed in DB)

**Database Views for Performance**:
```sql
-- Expected: review_queue view
CREATE VIEW review_queue AS SELECT ...

-- Expected: library_stats view
CREATE VIEW library_stats AS SELECT ...
```
**Status**: âŒ **MISSING** - No performance views created

### 2.2 Model Field Mismatches

#### **Document Status Handling**
**Expected**: `is_reviewed` boolean field drives review workflow
**Current**: âœ… Correctly implemented in models

**Expected**: Documents table links to processing_files via `document_id`
**Current**: âœ… Correctly implemented

#### **Processing File Status Values**
**Expected vs Current Status Enum Comparison**:

| Workflow Status | Current Enum | Match | Notes |
|-----------------|--------------|-------|-------|
| `uploading` | `UPLOADING` | âœ… | Perfect match |
| `uploaded` | `UPLOADED` | âœ… | Perfect match |
| `queued` | `QUEUED` | âœ… | Perfect match |
| `extracting` | `EXTRACTING` | âœ… | Perfect match |
| `analyzing` | `ANALYZING` | âœ… | Perfect match |
| `embedding` | `EMBEDDING` | âœ… | Perfect match |
| `review_pending` | `REVIEW_PENDING` | âœ… | Perfect match |
| `review_in_progress` | `REVIEW_IN_PROGRESS` | âœ… | Perfect match |
| `approved` | `APPROVED` | âœ… | Perfect match |

**Result**: âœ… **Status enums are perfectly aligned** - this is excellent!

---

## 3. Processing Pipeline Implementation Gaps

### 3.1 Background Processing Architecture

#### **âŒ Missing: Batch Status Calculation Logic**
**Expected**: Server-side calculation of batch status from file statuses
```python
# Expected implementation:
def calculate_batch_status(files: List[ProcessingFile]) -> str:
    if not files:
        return "created"

    status_counts = Counter(f.status for f in files)
    total_files = len(files)

    # All files approved
    if status_counts.get("approved", 0) == total_files:
        return "completed"
    # ... complex logic
```

**Current**: Basic status tracking exists, but no evidence of dynamic batch status calculation

#### **âŒ Missing: Automatic Processing Pipeline**
**Expected**: Files automatically progress through: uploaded â†’ queued â†’ extracting â†’ analyzing â†’ embedding â†’ review_pending

**Current**: Manual trigger endpoints exist (`POST /batch/{batch_id}/process`) but no evidence of automatic background processing

**Gap**: The workflow expects automatic processing, but current implementation seems to require manual triggers.

#### **âŒ Missing: Retry Logic and Error Handling**
**Expected**: Automatic retry with exponential backoff for failed processing
```python
# Expected:
async def queue_retry(file_id: str, max_retries: int = 3):
    delay = 2 ** file.retry_count * 60  # 2, 4, 8 minutes
    await schedule_retry(file_id, delay)
```

**Current**: Manual retry endpoint exists (`POST /files/{file_id}/retry`) but no automatic retry system

### 3.2 AI Integration Gaps

#### **âš ï¸ Unclear: AI Metadata Extraction Implementation**
**Expected**: Anthropic Claude integration with structured prompts
**Current**: AI service exists but implementation details not verified

**Critical Questions**:
- Is the Claude API integration actually implemented?
- Are the structured prompts from the workflow spec being used?
- Is confidence scoring implemented?

#### **âš ï¸ Unclear: Embedding Generation**
**Expected**: OpenAI embeddings with chunking strategy
**Current**: Embedding service exists but implementation details not verified

---

## 4. Review Workflow Implementation Issues

### 4.1 Missing Review Queue Features

#### **âŒ No Metadata Editing During Review**
**Expected Workflow**:
1. User clicks document in review queue
2. Metadata detail view loads with editable fields
3. User edits AI-extracted metadata
4. System saves changes
5. User approves or rejects

**Current Workflow**:
1. User can only approve or reject
2. No metadata editing capability
3. No preview of extracted text or AI analysis

**Impact**: Core human-in-the-loop workflow is broken

#### **âŒ Missing Document Preview**
**Expected**: Review interface shows document preview with extracted text
**Current**: Text extraction endpoint exists but no preview integration

#### **âŒ Missing Confidence Score Display**
**Expected**: AI confidence score displayed to help reviewers
**Current**: Confidence score exists in model but not exposed in review API

### 4.2 Review State Management Issues

#### **âŒ Missing Review Session Tracking**
**Expected**: Track when user starts reviewing (sets `review_in_progress` status)
**Current**: No session tracking - direct approve/reject only

**Expected Behavior**:
```python
# Start review session
POST /api/documents/{doc_id}/start-review
# â†’ Sets status to "review_in_progress"

# Save metadata changes
PUT /api/documents/{doc_id}/metadata
# â†’ Updates document metadata

# Complete review
POST /api/documents/{doc_id}/approve
# â†’ Sets status to "approved", moves to library
```

**Current Behavior**:
```python
# Only option:
POST /api/documents/approve/{file_id}
# â†’ Direct approval without review session
```

---

## 5. Frontend Integration Mismatches

### 5.1 Expected vs Available Data

#### **Library Statistics Dashboard**
**Expected Frontend Component**:
```typescript
const LibraryStats: React.FC = () => {
  const [stats, setStats] = useState<DocumentStats | null>(null);

  useEffect(() => {
    fetch('/api/documents/stats')  // âŒ This endpoint doesn't exist
      .then(res => res.json())
      .then(setStats);
  }, []);
```

**Current Reality**: Frontend would need to implement client-side aggregation or use a different endpoint pattern.

#### **Review Queue Component**
**Expected Data Structure**:
```typescript
interface QueueDocument {
  id: string;
  title: string;           // AI-extracted title
  confidence_score: number; // AI confidence
  preview_text: string;    // First 500 chars
  processing_status: string;
}
```

**Current API Response**: Different field names (`ai_title` vs `title`) and missing fields (`confidence_score`, `preview_text`)

#### **Real-time Updates**
**Expected**: WebSocket notifications for processing status updates
**Current**: âŒ No WebSocket implementation found

**Expected Notifications**:
- `document_ready_for_review`
- `batch_processing_complete`
- `processing_error`

---

## 6. Authentication and Security Analysis

### 6.1 âœ… Well Implemented

**JWT Authentication**: Properly implemented across all endpoints âœ…
**User Context**: Correctly extracts user ID from tokens âœ…
**RLS Policies**: Database-level security enabled âœ…

### 6.2 Missing Security Features

**Webhook Verification**:
- Expected: HMAC signature verification for webhooks
- Current: Basic webhook endpoints exist but no signature verification

**File Validation**:
- Expected: Comprehensive file validation including magic number checks
- Current: Basic MIME type and size validation implemented

---

## 7. Performance and Scalability Gaps

### 7.1 Missing Database Optimizations

#### **âŒ Missing Critical Indexes**
**Expected Performance Indexes**:
```sql
-- Search optimization
CREATE INDEX idx_documents_search_title ON documents USING gin(to_tsvector('english', title));
CREATE INDEX idx_documents_search_summary ON documents USING gin(to_tsvector('english', summary));

-- Batch processing queries
CREATE INDEX idx_processing_files_batch_status ON processing_files(batch_id, status);

-- Performance for queue queries
CREATE INDEX idx_documents_queue ON documents(is_reviewed, created_at) WHERE is_reviewed = false;
```

**Current**: Only basic indexes for citation, doc_type, doc_category exist

#### **âŒ Missing Database Views**
**Expected**: Pre-computed views for expensive queries
**Current**: No database views for performance optimization

### 7.2 Missing Caching Strategy

**Expected**: Caching for frequently accessed data like library statistics
**Current**: No evidence of caching implementation

---

## 8. Error Handling and Monitoring Gaps

### 8.1 âŒ Missing Processing Logs System

**Expected**: Comprehensive logging system for UI display
```python
# Expected log entries:
{
  "job_id": "uuid",
  "log_message": "Upload completed successfully",
  "log_level": "success",
  "created_at": "timestamp"
}
```

**Current**: Server logging exists but no user-facing log system

### 8.2 âŒ Missing Webhook Notification System

**Expected**: Real-time status updates via webhooks
**Current**: Webhook endpoints exist but no notification system implementation

---

## 9. Testing Coverage Analysis

### 9.1 âœ… Strong Unit Test Foundation

**Current State**: 30/30 unit tests passing (100%) âœ…
**Coverage**: File service, enums, basic infrastructure well tested âœ…

### 9.2 âŒ Missing Integration and E2E Tests

**Expected Integration Tests**:
- Complete upload â†’ processing â†’ review â†’ approval workflow
- API endpoint integration testing
- Database operation testing

**Expected E2E Tests**:
- End-to-end document ingestion workflow
- Frontend component integration
- Real processing pipeline testing

**Current**: No integration or E2E tests found

---

## Summary of Critical Issues

### ðŸ”´ **Blocking Issues** (Prevent Basic Functionality)

1. **Missing Review Queue Endpoint** - Frontend cannot display review queue
2. **Missing Metadata Update Endpoint** - Users cannot edit AI-extracted metadata
3. **Missing Library Statistics Endpoint** - Dashboard cannot display counts
4. **No Background Processing Pipeline** - Files don't automatically progress through stages

### ðŸŸ¡ **Major Issues** (Degraded User Experience)

5. **Missing Processing Logs** - No visibility into system activity
6. **Missing Batch Status Calculation** - Incorrect status display
7. **Missing Document Preview** - Cannot preview text during review
8. **Missing Real-time Updates** - No live status updates

### ðŸŸ¢ **Minor Issues** (Polish and Performance)

9. **Missing Database Indexes** - Performance degradation at scale
10. **Missing Webhook Notifications** - No real-time frontend updates
11. **Missing Integration Tests** - Reduced system reliability
12. **Missing Error Recovery** - No automatic retry system

---

# Implementation TODO List

## Phase 1: Critical API Endpoints (Week 1-2)

### ðŸ”´ **Priority 1: Review Queue System**

#### **TODO 1.1: Implement Review Queue Endpoint**
```python
# File: app/api/documents.py
@router.get("/queue", tags=["Documents"])
async def get_review_queue(current_user: Dict[str, Any] = Depends(get_current_user)):
    """Get documents pending review with full metadata."""

    # Query from workflow spec:
    query = """
    SELECT
        d.*,
        pf.original_filename,
        pf.file_size,
        pf.created_at as uploaded_at,
        pf.status as processing_status,
        pf.batch_id,
        LEFT(pf.extracted_text, 500) as preview_text
    FROM documents d
    JOIN processing_files pf ON d.id = pf.document_id
    WHERE d.is_reviewed = false
    AND pf.status IN ('review_pending', 'review_in_progress')
    ORDER BY pf.created_at ASC
    """
```

**Acceptance Criteria:**
- [ ] Returns documents with `is_reviewed = false`
- [ ] Includes AI-extracted metadata (title, doc_type, confidence_score)
- [ ] Includes preview_text (first 500 chars of extracted text)
- [ ] Proper error handling and authentication
- [ ] Matches exact response format from workflow spec

#### **TODO 1.2: Implement Document Metadata Update Endpoint**
```python
# File: app/api/documents.py
@router.put("/{document_id}/metadata", tags=["Documents"])
async def update_document_metadata(
    document_id: str,
    metadata: DocumentUpdate,
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """Update document metadata during review."""
```

**Acceptance Criteria:**
- [ ] Updates document metadata in documents table
- [ ] Sets processing_files status to 'review_in_progress' when first accessed
- [ ] Validates enum values for doc_type and doc_category
- [ ] Returns updated document metadata
- [ ] Tracks review session (reviewed_by, review_started_at)

#### **TODO 1.3: Implement Document Library Statistics Endpoint**
```python
# File: app/api/documents.py
@router.get("/stats", tags=["Documents"])
async def get_document_stats(user = Depends(get_current_user)):
    """Get document counts by type for library dashboard."""

    # Use SQL aggregation for performance:
    query = """
    SELECT
        doc_type,
        COUNT(*) as count
    FROM documents
    WHERE is_reviewed = true
    AND is_deleted = false
    AND is_archived = false
    GROUP BY doc_type
    """
```

**Acceptance Criteria:**
- [ ] Returns counts for each document type
- [ ] Filters by `is_reviewed = true` (library documents only)
- [ ] Excludes deleted and archived documents
- [ ] Matches exact response format from workflow spec
- [ ] Performance optimized with database aggregation

#### **TODO 1.4: Fix Document Approval Endpoint Pattern**
**Current Issue**: Uses `POST /approve/{file_id}` instead of `POST /{document_id}/approve`

**Action Required:**
- [ ] Change endpoint URL pattern to match workflow spec
- [ ] Use document_id instead of file_id in URL
- [ ] Update approval logic to work with document_id
- [ ] Maintain backward compatibility during transition
- [ ] Update all references in codebase

---

## Phase 2: Processing Pipeline Automation (Week 2-3)

### ðŸŸ¡ **Priority 2: Background Processing System**

#### **TODO 2.1: Implement Automatic Processing Pipeline**
**Current Issue**: Manual processing triggers only, no automatic background processing

```python
# File: app/services/processing_service.py
class AutomaticProcessingPipeline:
    async def on_file_uploaded(self, file_id: str):
        """Automatically trigger when file status = 'uploaded'"""
        await self.queue_text_extraction(file_id)

    async def on_text_extracted(self, file_id: str):
        """Automatically trigger when status = 'extracting' â†’ 'analyzing'"""
        await self.queue_ai_analysis(file_id)

    async def on_metadata_extracted(self, file_id: str):
        """Automatically trigger when status = 'analyzing' â†’ 'embedding'"""
        await self.queue_embedding_generation(file_id)
```

**Acceptance Criteria:**
- [ ] Files automatically progress through processing pipeline
- [ ] No manual triggers required for normal workflow
- [ ] Status transitions trigger next processing step
- [ ] Error handling with automatic retry logic
- [ ] Background job queue implementation (Celery/RQ)

#### **TODO 2.2: Implement Batch Status Calculation Logic**
```python
# File: app/services/processing_service.py
def calculate_batch_status(files: List[ProcessingFile]) -> str:
    """Calculate batch status from individual file statuses."""
    if not files:
        return "created"

    status_counts = Counter(f.status for f in files)
    total_files = len(files)

    # All files approved
    if status_counts.get("approved", 0) == total_files:
        return "completed"

    # Some files approved, others pending
    if status_counts.get("approved", 0) > 0:
        return "partially_approved"

    # Any files ready for review
    if status_counts.get("review_pending", 0) > 0 or status_counts.get("review_in_progress", 0) > 0:
        return "review_ready"

    # Continue with complex logic from workflow spec...
```

**Acceptance Criteria:**
- [ ] Implements exact logic from workflow specification
- [ ] Called whenever file status changes
- [ ] Updates processing_jobs.status automatically
- [ ] Performance optimized for large batches
- [ ] Unit tests covering all status combinations

#### **TODO 2.3: Implement Automatic Retry System**
```python
# File: app/services/retry_service.py
class RetryService:
    async def queue_retry(self, file_id: str, max_retries: int = 3):
        """Queue file for retry if under retry limit."""
        file = await get_processing_file(file_id)

        if file.retry_count < max_retries:
            # Schedule retry with exponential backoff
            delay = 2 ** file.retry_count * 60  # 2, 4, 8 minutes
            await schedule_retry(file_id, delay)
        else:
            # Max retries exceeded, mark as permanently failed
            await update_file_status(file_id, "extraction_failed",
                                    error_message="Max retries exceeded")
```

**Acceptance Criteria:**
- [ ] Automatic retry for failed processing steps
- [ ] Exponential backoff delay (2, 4, 8 minutes)
- [ ] Maximum 3 retry attempts
- [ ] Proper error tracking and logging
- [ ] Integration with background job system

---

## Phase 3: Missing API Features (Week 3-4)

### ðŸŸ¡ **Priority 3: Processing Logs and Monitoring**

#### **TODO 3.1: Implement Processing Logs Endpoint**
```python
# File: app/api/processing.py
@router.get("/logs", tags=["Processing"])
async def get_processing_logs(
    limit: int = 100,
    user = Depends(get_current_user)
):
    """Get processing logs for UI display."""

    query = """
    SELECT
        pj.id as job_id,
        pj.status as job_status,
        pj.created_at,
        pj.total_files,
        pj.completed_files,
        pj.failed_files,
        CASE
            WHEN pj.status = 'failed' THEN 'Upload failed: Batch upload failed'
            WHEN pj.status = 'completed' THEN 'Upload completed successfully'
            ELSE 'Starting batch upload of ' || pj.total_files || ' document(s)'
        END as log_message,
        CASE
            WHEN pj.status = 'failed' THEN 'error'
            WHEN pj.status = 'completed' THEN 'success'
            ELSE 'info'
        END as log_level
    FROM processing_jobs pj
    ORDER BY pj.created_at DESC
    LIMIT {limit}
    """
```

**Acceptance Criteria:**
- [ ] Returns formatted log entries for frontend display
- [ ] Includes job status, timestamps, file counts
- [ ] Proper log levels (info, success, warning, error)
- [ ] Pagination support
- [ ] Real-time updates capability

#### **TODO 3.2: Enhanced Job Status Endpoint**
**Update existing**: `GET /api/documents/processing-status/{batch_id}`

**Required Changes:**
- [ ] Rename to match workflow spec: `GET /api/processing/jobs/{job_id}`
- [ ] Include calculated batch status from TODO 2.2
- [ ] Include individual file details
- [ ] Add progress percentage calculation
- [ ] Optimize query performance

---

## Phase 4: Database and Performance (Week 4-5)

### ðŸŸ¢ **Priority 4: Database Optimizations**

#### **TODO 4.1: Create Missing Database Indexes**
```sql
-- File: supabase/migrations/{timestamp}_performance_indexes.sql

-- Search optimization
CREATE INDEX IF NOT EXISTS idx_documents_search_title
ON documents USING gin(to_tsvector('english', title));

CREATE INDEX IF NOT EXISTS idx_documents_search_summary
ON documents USING gin(to_tsvector('english', summary));

-- Status filtering
CREATE INDEX IF NOT EXISTS idx_documents_review_status
ON documents(is_reviewed, is_deleted, is_archived);

CREATE INDEX IF NOT EXISTS idx_processing_files_status
ON processing_files(status);

-- Batch processing queries
CREATE INDEX IF NOT EXISTS idx_processing_files_batch_status
ON processing_files(batch_id, status);

-- Performance for queue queries
CREATE INDEX IF NOT EXISTS idx_documents_queue
ON documents(is_reviewed, created_at) WHERE is_reviewed = false;
```

#### **TODO 4.2: Create Database Views for Performance**
```sql
-- File: supabase/migrations/{timestamp}_performance_views.sql

-- Review Queue View
CREATE OR REPLACE VIEW review_queue AS
SELECT
    d.id,
    d.title,
    d.doc_type,
    d.doc_category,
    d.confidence_score,
    d.summary,
    pf.original_filename,
    pf.file_size,
    pf.status as processing_status,
    pf.created_at as uploaded_at,
    pf.batch_id,
    LEFT(pf.extracted_text, 500) as preview_text
FROM documents d
JOIN processing_files pf ON d.id = pf.document_id
WHERE d.is_reviewed = false
AND pf.status IN ('review_pending', 'review_in_progress');

-- Library Statistics View
CREATE OR REPLACE VIEW library_stats AS
SELECT
    COUNT(*) FILTER (WHERE doc_type = 'book') as books_textbooks,
    COUNT(*) FILTER (WHERE doc_type = 'article') as articles_publications,
    COUNT(*) FILTER (WHERE doc_type = 'statute') as statutes_codes,
    COUNT(*) FILTER (WHERE doc_type = 'case_law') as case_law,
    COUNT(*) FILTER (WHERE doc_type = 'expert_report') as expert_reports,
    COUNT(*) FILTER (WHERE doc_type = 'other') as other_documents,
    COUNT(*) as total_documents
FROM documents
WHERE is_reviewed = true
AND is_deleted = false
AND is_archived = false;
```

#### **TODO 4.3: Add Missing Schema Fields**
```sql
-- File: supabase/migrations/{timestamp}_missing_schema_fields.sql

-- Add webhook support to processing_jobs
ALTER TABLE processing_jobs
ADD COLUMN IF NOT EXISTS webhook_url text,
ADD COLUMN IF NOT EXISTS webhook_secret text,
ADD COLUMN IF NOT EXISTS last_webhook_at timestamp with time zone;

-- Enhance error tracking in processing_files
ALTER TABLE processing_files
ADD COLUMN IF NOT EXISTS error_details jsonb,
ADD COLUMN IF NOT EXISTS retry_strategy text DEFAULT 'exponential_backoff';

-- Add review session tracking
ALTER TABLE processing_files
ADD COLUMN IF NOT EXISTS review_started_at timestamp with time zone,
ADD COLUMN IF NOT EXISTS reviewed_by uuid REFERENCES auth.users(id);
```

---

## Phase 5: Real-time Features (Week 5-6)

### ðŸŸ¢ **Priority 5: WebSocket and Webhooks**

#### **TODO 5.1: Implement WebSocket Notifications**
```python
# File: app/websocket.py
from fastapi import WebSocket
import json

class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    async def broadcast_notification(self, notification: dict):
        for connection in self.active_connections:
            await connection.send_text(json.dumps(notification))

# File: app/main.py
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    # Handle real-time notifications
```

**Notification Types to Implement:**
- [ ] `document_ready_for_review` - When file reaches review_pending status
- [ ] `batch_processing_complete` - When all files in batch are processed
- [ ] `processing_error` - When processing fails
- [ ] `document_approved` - When document is approved and moved to library

#### **TODO 5.2: Enhanced Webhook System**
```python
# File: app/services/webhook_service.py
class WebhookService:
    async def send_webhook_notification(self, event_type: str, data: dict):
        """Send webhook notification with HMAC signature verification."""

        payload = {
            "type": event_type,
            "data": data,
            "timestamp": datetime.utcnow().isoformat()
        }

        # Add HMAC signature for security
        signature = generate_hmac_signature(payload, webhook_secret)

        # Send to configured webhook URL
        await send_webhook(webhook_url, payload, signature)
```

**Acceptance Criteria:**
- [ ] HMAC signature verification for security
- [ ] Retry logic for failed webhook deliveries
- [ ] Webhook URL configuration per processing job
- [ ] Event types matching workflow specification

---

## Phase 6: Testing and Reliability (Week 6-7)

### ðŸŸ¢ **Priority 6: Integration and E2E Tests**

#### **TODO 6.1: Integration Test Suite**
```python
# File: tests/integration/test_complete_workflow.py
class TestCompleteWorkflow:
    async def test_upload_to_library_workflow(self):
        """Test complete document workflow end-to-end."""

        # 1. Upload document
        upload_response = await upload_test_document()
        assert upload_response.success_count == 1

        # 2. Wait for processing completion
        await wait_for_processing_complete(upload_response.job_id)

        # 3. Verify document in review queue
        queue = await get_review_queue()
        assert len(queue.queue) >= 1

        # 4. Update metadata and approve
        document = queue.queue[0]
        await update_document_metadata(document.id, test_metadata)
        await approve_document(document.id)

        # 5. Verify document in library
        library_docs = await get_library_documents()
        approved_doc = find_document_by_title(library_docs, test_metadata.title)
        assert approved_doc.is_reviewed == True
```

**Test Coverage Required:**
- [ ] Complete upload â†’ processing â†’ review â†’ approval workflow
- [ ] Error handling and retry scenarios
- [ ] Batch processing with mixed success/failure
- [ ] API endpoint integration testing
- [ ] Database transaction integrity

#### **TODO 6.2: Performance and Load Testing**
```python
# File: tests/performance/test_load.py
class TestPerformance:
    async def test_concurrent_uploads(self):
        """Test system under concurrent upload load."""

        # Simulate 10 concurrent users uploading 5 files each
        tasks = [upload_batch_files(5) for _ in range(10)]
        results = await asyncio.gather(*tasks)

        # Verify all uploads succeeded
        for result in results:
            assert result.success_count == 5
            assert result.error_count == 0
```

**Performance Targets:**
- [ ] Handle 50 concurrent file uploads
- [ ] Process 100 documents per hour
- [ ] Review queue response time < 500ms
- [ ] Library search response time < 1s

---

## Phase 7: AI Integration Verification (Week 7-8)

### ðŸ”¶ **Priority 7: AI Service Implementation Audit**

#### **TODO 7.1: Verify AI Metadata Extraction**
**Action Required**: Comprehensive audit of current AI service implementation

**Verification Checklist:**
- [ ] **Claude API Integration**: Verify actual Anthropic API calls are implemented
- [ ] **Structured Prompts**: Check prompts match workflow specification exactly
- [ ] **Confidence Scoring**: Verify AI confidence scores are calculated and stored
- [ ] **Metadata Fields**: Ensure all expected fields are extracted (case_name, citation, etc.)
- [ ] **Error Handling**: Verify proper handling of AI API failures and timeouts

#### **TODO 7.2: Verify Embedding Generation**
**Action Required**: Comprehensive audit of current embedding service

**Verification Checklist:**
- [ ] **OpenAI Integration**: Verify actual OpenAI API calls for embeddings
- [ ] **Chunking Strategy**: Check text chunking matches workflow spec (1000 chars, 200 overlap)
- [ ] **Vector Storage**: Verify embeddings are stored correctly in document_chunks table
- [ ] **Search Implementation**: Verify vector similarity search is functional

#### **TODO 7.3: Verify Text Extraction**
**Action Required**: Audit extraction service implementation

**Verification Checklist:**
- [ ] **PDF Processing**: Verify PyMuPDF is working for PDF text extraction
- [ ] **DOCX Processing**: Verify DOCX text extraction is implemented
- [ ] **Text Quality**: Check extracted text quality and formatting
- [ ] **Error Handling**: Verify handling of corrupted or protected files

---

## Implementation Timeline

### **Week 1-2: Critical API Endpoints**
- Review queue endpoint
- Metadata update endpoint
- Library statistics endpoint
- Fix approval endpoint pattern

### **Week 3-4: Processing Pipeline**
- Automatic background processing
- Batch status calculation
- Automatic retry system
- Processing logs endpoint

### **Week 5-6: Performance and Features**
- Database indexes and views
- WebSocket notifications
- Enhanced webhook system
- Missing schema fields

### **Week 7-8: Testing and AI Audit**
- Integration test suite
- Performance testing
- AI service verification
- End-to-end workflow testing

---

## Success Metrics

### **Phase 1 Success Criteria:**
- [ ] Frontend can display review queue with proper metadata
- [ ] Users can edit AI-extracted metadata during review
- [ ] Library statistics display correctly
- [ ] Document approval workflow functions end-to-end

### **Phase 2 Success Criteria:**
- [ ] Documents automatically progress through processing pipeline
- [ ] Batch status displays accurately based on file statuses
- [ ] Failed processing automatically retries with backoff
- [ ] Processing logs display system activity

### **Phase 3 Success Criteria:**
- [ ] System performs well under concurrent load
- [ ] Real-time status updates work via WebSocket
- [ ] All database queries are optimized with proper indexes
- [ ] Complete test coverage for all workflows

### **Final Success Criteria:**
- [ ] **100% Workflow Compliance**: Backend matches workflow specification exactly
- [ ] **Production Ready**: System handles production load and error scenarios
- [ ] **Frontend Compatible**: All endpoints return data in expected format
- [ ] **Reliable**: Comprehensive test coverage with integration and E2E tests

---

## Risk Mitigation

### **High Risk Items:**
1. **AI Service Integration**: May require significant rework if not properly implemented
2. **Background Processing**: Complex to implement reliable job queue system
3. **Performance**: Database optimization critical for production scale

### **Mitigation Strategies:**
1. **AI Audit First**: Verify AI implementation before building dependent features
2. **Incremental Testing**: Test each component thoroughly before integration
3. **Performance Monitoring**: Add metrics and monitoring from the start

This comprehensive implementation plan provides a clear roadmap to align the webapp-backend with the complete workflow specification, ensuring a production-ready document ingestion system.
